import os
import glob
import tensorflow as tf

class MUSDB:
    """MUSDB dataset loader.
    Use other opensource vocoder settings, 16bit, sr: 22050.
    """
    SR = 22050

    def __init__(self, config, data_dir=None):
        """Initializer.
        Args:
            config: Config, dataset configuration.
            data_dir: str, dataset directory
                , defaults to "~/tensorflow_datasets".
            download: bool, download dataset or not.
            from_tfds: bool, load from tfrecord generated by tfds or read raw audio.
        """
        self.config = config
        self.rawset = self.load_data("train", data_dir)
        self.valset = self.load_data("val", data_dir)

        self.normalized = None

    def load_data(self, subset="train", data_dir=None):
        """Load dataset from tfrecord or raw audio files.
        Args:
            data_dir: str, dataset directory.
        Returns:
            tf.data.Dataset, data loader.
        """
        if subset == "train":
            mixture_files = glob.glob(os.path.join(data_dir, "*mixture.wav"))
            for track in self.config.eval_tracks:
                mixture_files = [x for x in mixture_files if track + "_" not in x]
        else:
            mixture_files = []
            for track in self.config.eval_tracks:
                mixture_files += [x for x in glob.glob(os.path.join(data_dir, "*mixture.wav")) if (track + "_" in x) and \
                    ("_" + track + "_" not in track)]
            mixture_files = [x for x in mixture_files if "silence" not in x]
        # generate file lists
        files = tf.data.Dataset.from_tensor_slices(
            [(mix, mix.replace("_mixture.", "_vocals."), mix.replace("_mixture.", "_accompaniment.")) for mix in mixture_files])

        return files.map(MUSDB._load_audio)

    @staticmethod
    def _load_audio(paths):
        """Load audio with tf apis.
        Args:
            path: str, wavfile path to read.
        Returns:
            tf.Tensor, [T], mono audio in range (-1, 1).
        """
        mixture_audio, _ = tf.audio.decode_wav(tf.io.read_file(paths[0]), desired_channels=1)
        vocal_audio, _ = tf.audio.decode_wav(tf.io.read_file(paths[1]), desired_channels=1)
        accomp_audio, _ = tf.audio.decode_wav(tf.io.read_file(paths[2]), desired_channels=1)
        return tf.squeeze(mixture_audio, axis=-1), tf.squeeze(vocal_audio, axis=-1), tf.squeeze(accomp_audio, axis=-1)

    def normalizer(self, frames=16000):
        """Create dataset normalizer, make fixed size segment in range(-1, 1).
        Args:
            frames: int, segment size, frame unit.
            from_tfds: bool, whether use tfds tfrecord or raw audio.
        Returns:
            Callable, normalizer.
        """
        def normalize(mixture_signal, vocal_signal, accomp_signal):
            """Normalize datum.
            Args:
                mixture_signal: tf.Tensor, [T], mono audio in range (-1, 1).
                vocal_signal: tf.Tensor, [T], mono audio in range (-1, 1).
                accomp_signal: tf.Tensor, [T], mono audio in range (-1, 1).
            Returns:
                tf.Tensor, [frames], fixed size mixture signal in range (-1, 1). 
                tf.Tensor, [frames], fixed size vocal signal in range (-1, 1). 
                tf.Tensor, [frames], fixed size accomp signal in range (-1, 1). 
            """
            nonlocal frames
            frames = frames // self.config.hop * self.config.hop
            start = tf.random.uniform(
                (), 0, tf.shape(vocal_signal)[0] - frames, dtype=tf.int32)
            return mixture_signal[start:start + frames], vocal_signal[start:start + frames], accomp_signal[start:start + frames]
        return normalize
        
    def dataset(self):
        """Generate dataset.
        """
        if self.normalized is None:
            self.normalized = self.rawset \
                .map(self.normalizer(self.config.frames)) \
                .batch(self.config.batch)
        return self.normalized

    def test_dataset(self):
        """Generate dataset.
        """
        return self.valset \
            .map(self.normalizer(self.config.frames)) \
            .batch(self.config.batch)

    def validation(self):
        """Generate dataset.
        """
        # Getting longer samples for evaluation
        return self.valset \
            .map(self.normalizer(self.config.frames*4)) \
            .batch(1)
